{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/hackernoon/building-a-bigram-hidden-markov-model-for-part-of-speech-tagging-1b784a87ab2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import ssl\n",
    "from Matrix import Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skindanje raznih corpusa s weba\n",
    "#ovo radim jer iz zbog manjka https-a ne radi download\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "#nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the training data\n",
    "from nltk.corpus import brown\n",
    "\n",
    "brown_sents = brown.sents(categories = \"adventure\")\n",
    "\n",
    "#moramo ga konvertirati u listu\n",
    "brown_tagged_sents = list(brown.tagged_sents(categories = \"adventure\", tagset = \"universal\"))\n",
    "\n",
    "#podjela\n",
    "size = int(0.9 * len(brown_tagged_sents))\n",
    "random.shuffle(brown_tagged_sents)\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training our bigram model\n",
    "from BigramModel import BigramModel\n",
    "from AugmentedSuffixTree import AugmentedSuffixTree\n",
    "\n",
    "bigram = BigramModel(5, 25)\n",
    "\n",
    "bigram.train(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating our bigram module\n",
    "from AugmentedSuffixTreeFactory import AugmentedSuffixTreeFactory as TreeFactory\n",
    "factory = TreeFactory(bigram, 5, 25)\n",
    "lowerCaseTree = factory.buildLowerCaseTree()\n",
    "upperCaseTree = factory.buildUpperCaseTree()\n",
    "\n",
    "evaluation = bigram.evaluate(upperCaseTree, lowerCaseTree, test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #print(lowerCaseTree.nodes)\n",
    "    #print(upperCaseTree.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7223536369012419\n"
     ]
    }
   ],
   "source": [
    "print(evaluation.evaluate())\n",
    "# print(evaluation.sentences)\n",
    "# print(evaluation.taggedSentences)\n",
    "# print(evaluation.goldenTaggedSentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
